# -*- coding: utf-8 -*-
"""vgg-16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RAZZt_6crG-1mgvA3gYJHchouknWRSKd
"""

from google.colab import drive
drive.mount('/content/drive')

from keras.models import Sequential
from keras.layers import Flatten, Dense, BatchNormalization, Dropout
from keras.applications import VGG16
import matplotlib.pyplot as plt
import cv2
import numpy as np
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.preprocessing.image import ImageDataGenerator

train_path = '/content/drive/MyDrive/AYZEK-Kanarya/dataset/train'
test_path = '/content/drive/MyDrive/AYZEK-Kanarya/dataset/test'
val_path = '/content/drive/MyDrive/AYZEK-Kanarya/dataset/val'

train_data_gen = ImageDataGenerator(rescale=1/255) # Ã–lÃ§eklendirme
test_data_gen = ImageDataGenerator(rescale=1/255)
val_data_gen = ImageDataGenerator(rescale=1/255)

"""GÃ¶rÃ¼ntÃ¼ veri iÅŸleme sÃ¼recinde, piksel deÄŸerleri genellikle 0 ile 255 arasÄ±nda olur.
Ancak, bu deÄŸerlerin bir modelin eÄŸitilmesi iÃ§in uygun hale getirilmesi gerekir.
Bu nedenle, genellikle piksel deÄŸerlerini 0 ile 1 arasÄ±nda olacak ÅŸekilde Ã¶lÃ§eklendirilirler.
Bunu yapmanÄ±n bir yolu, piksel deÄŸerlerini 255'e bÃ¶lmektir.
Yani, her piksel deÄŸeri 255'e bÃ¶lÃ¼nerek 0 ile 1 arasÄ±nda bir deÄŸer elde edilir.
Bu nedenle, **`rescale(1/255)`** yÃ¶ntemi, gÃ¶rÃ¼ntÃ¼ verilerinin piksel deÄŸerlerini yeniden Ã¶lÃ§eklendirerek 0 ile 1 arasÄ±nda bir deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
Bu, modelin daha iyi Ã¶ÄŸrenme yapmasÄ±nÄ± saÄŸlar, Ã§Ã¼nkÃ¼ genellikle daha kÃ¼Ã§Ã¼k sayÄ±larla daha iyi performans elde edilir.
"""

train_generator = train_data_gen.flow_from_directory(
        train_path,
        target_size=(224,224), # GÃ¶rÃ¼ntÃ¼ boyutlarÄ±
        batch_size=16,
        class_mode='categorical')  # SÄ±nÄ±f modu, Ã§ok sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rma olduÄŸu iÃ§in 'categorical'

"""ğŸ‘†ğŸ»ğŸ‘†ğŸ»ğŸ‘†ğŸ»
Bir veri yÃ¼kleyici (data loader) oluÅŸturulur.
Bu yÃ¼kleyici, belirtilen dizindeki gÃ¶rÃ¼ntÃ¼leri yÃ¼kler, onlarÄ± belirtilen boyuta yeniden boyutlandÄ±rÄ±r,
belirtilen batch boyutunda gruplar halinde verir ve hedef sÄ±nÄ±flarÄ± kategorik olarak kodlar.
Bu yÃ¼kleyici daha sonra model eÄŸitimi iÃ§in kullanÄ±labilir.
"""

test_generator = test_data_gen.flow_from_directory(
    test_path,
    target_size=(224,224),  # GÃ¶rÃ¼ntÃ¼ boyutlarÄ±
    batch_size=16,
    class_mode='categorical'  # SÄ±nÄ±f modu, Ã§ok sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rma olduÄŸu iÃ§in 'categorical'
)

val_generator = val_data_gen.flow_from_directory(
    val_path,
    target_size=(224,224),  # GÃ¶rÃ¼ntÃ¼ boyutlarÄ±
    batch_size=16,
    class_mode='categorical'  # SÄ±nÄ±f modu, Ã§ok sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rma olduÄŸu iÃ§in 'categorical'
)

vgg = VGG16(
    input_shape=(224,224,3),
    weights='imagenet',
    include_top=False)

"""**include_top=False** olduÄŸunda VGG16 modeli, tamamen baÄŸlÄ± katmanlar (fully connected layer'lar) olmadan oluÅŸturulur.
Bu durumda, modelin sadece Ã¶zellik Ã§Ä±karma (feature extraction) kÄ±smÄ± oluÅŸturulur.
Bu, modelin Ã¶zellik Ã§Ä±karma amacÄ±yla kullanÄ±lmasÄ±nÄ± saÄŸlar. Yani, bu model, gÃ¶rÃ¼ntÃ¼lerin dÃ¼ÅŸÃ¼k, orta ve yÃ¼ksek seviyeli Ã¶zelliklerini Ã§Ä±karmak iÃ§in kullanÄ±labilir,
ancak sÄ±nÄ±flandÄ±rma katmanlarÄ± olmadÄ±ÄŸÄ± iÃ§in sÄ±nÄ±flandÄ±rma yapamaz.
"""

model = Sequential()
model.add(vgg)
model.add(BatchNormalization())
model.add(Flatten())
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(4096, activation='relu'))
model.add(Dense(4 , activation='softmax'))

"""**softmax aktivasyon fonksiyonu** genellikle Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma problemleri iÃ§in kullanÄ±lÄ±r.
Bu fonksiyon, modelin Ã§Ä±ktÄ±larÄ±nÄ± olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±na dÃ¶nÃ¼ÅŸtÃ¼rerek, sÄ±nÄ±f olasÄ±lÄ±klarÄ±nÄ± hesaplamak iÃ§in idealdir.
Ã–zellikle sÄ±nÄ±flandÄ±rma problemlerinde, modelin Ã§Ä±kÄ±ÅŸÄ± sÄ±nÄ±f etiketlerine karÅŸÄ±lÄ±k gelen olasÄ±lÄ±klar kÃ¼mesi olarak yorumlanabilir.
softmax fonksiyonu, bu olasÄ±lÄ±klarÄ±n toplamÄ±nÄ±n 1'e eÅŸit olmasÄ±nÄ± saÄŸlar, bu da her bir sÄ±nÄ±f iÃ§in bir olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± oluÅŸturur.

**`BatchNormalization`** katmanÄ±, normalleÅŸtirme iÅŸlemini gerÃ§ekleÅŸtirir. Her bir batch'teki (bir grup veri) Ã¶zellik vektÃ¶rlerinin ortalamasÄ±nÄ± sÄ±fÄ±ra ve varyansÄ±nÄ± bir birime getirir. Bunu yaparak, her bir batch'in daÄŸÄ±lÄ±mÄ±nÄ± daha istikrarlÄ± hale getirir ve gradyanlarÄ±n daha tutarlÄ± bir ÅŸekilde akmasÄ±nÄ± saÄŸlar.

NormalleÅŸtirme iÅŸlemi, aÅŸaÄŸÄ±daki adÄ±mlarla gerÃ§ekleÅŸtirilir:

- Ortalama Hesaplama: Her bir Ã¶zellik (feature) boyunca batch iÃ§indeki Ã¶zellik
vektÃ¶rlerinin ortalamasÄ± hesaplanÄ±r.

- Varyans Hesaplama: Her bir Ã¶zellik boyunca batch iÃ§indeki Ã¶zellik vektÃ¶rlerinin varyansÄ± hesaplanÄ±r.

- NormalleÅŸtirme: Ã–zellik vektÃ¶rleri, ortalama deÄŸerden Ã§Ä±karÄ±larak (ortalamadan Ã§Ä±karÄ±larak) merkezlenir ve ardÄ±ndan varyansla bÃ¶lÃ¼nerek Ã¶lÃ§eklenir.

- Ã–lÃ§ekleme ve KaydÄ±rma: NormalleÅŸtirilmiÅŸ Ã¶zellik vektÃ¶rleri, bir Ã¶lÃ§ek (scale) ve bir kaydÄ±rma (shift) parametresi ile Ã§arpÄ±lÄ±r ve eklenir. Bu parametreler, modelin Ã¶ÄŸrenilebilir parametreleridir ve her bir Ã¶zellik kanalÄ± iÃ§in ayrÄ± ayrÄ± hesaplanÄ±r.

Bu adÄ±mlar, her bir batch'teki verilerin ortalamasÄ±nÄ± ve varyansÄ±nÄ± standartlaÅŸtÄ±rarak eÄŸitim sÃ¼recini daha hÄ±zlÄ± ve daha istikrarlÄ± hale getirir. SonuÃ§ olarak, modelin daha hÄ±zlÄ± Ã¶ÄŸrenmesine ve daha iyi sonuÃ§lar elde etmesine yardÄ±mcÄ± olur.
"""

model.summary()

model.compile(optimizer='Adadelta', loss='categorical_crossentropy', metrics=['accuracy'])

"""SÄ±nÄ±flandÄ±rma problemleri iÃ§in en yaygÄ±n olarak kullanÄ±lan optimizer genellikle **Adam optimizeridir.** Adam, adaptif Ã¶ÄŸrenme oranÄ± ve momentumun bir kombinasyonunu kullanarak gradyan iniÅŸini gerÃ§ekleÅŸtirir. Bu, birÃ§ok sÄ±nÄ±flandÄ±rma probleminde etkili sonuÃ§lar veren gÃ¼Ã§lÃ¼ bir optimizerdÄ±r.

Adam optimizerinin birkaÃ§ avantajÄ± vardÄ±r:

- HÄ±zlÄ± ve Etkili: Adam, genellikle diÄŸer optimizerlere kÄ±yasla daha hÄ±zlÄ± ve daha etkili bir ÅŸekilde eÄŸitim saÄŸlar.

- Adaptif Ã–ÄŸrenme OranÄ±: Adam, her parametre iÃ§in ayrÄ± ayrÄ± adaptif bir Ã¶ÄŸrenme oranÄ± saÄŸlar. Bu, modelin hÄ±zlÄ± ve dengeli bir ÅŸekilde eÄŸitilmesine yardÄ±mcÄ± olur.

- Momentumun KullanÄ±mÄ±: Adam, gradyanÄ±n momentumunu da dikkate alÄ±r, bu da eÄŸitim sÃ¼recinin daha istikrarlÄ± olmasÄ±na ve yerel minimumlara daha az sÄ±kÄ±ÅŸmasÄ±na yardÄ±mcÄ± olur.

- Parametre DÃ¼zenleme: Adam, genellikle overfitting'i azaltmaya yardÄ±mcÄ± olan parametre dÃ¼zenleme (regularization) Ã¶zelliÄŸine sahiptir.


**`1) Gradyan:`** Bir fonksiyonun en bÃ¼yÃ¼k artÄ±ÅŸÄ±nÄ± gÃ¶steren vektÃ¶r. TÃ¼revi alÄ±nan bir fonksiyonun gradyanÄ±, fonksiyonun artÄ±ÅŸ hÄ±zÄ±nÄ±n en bÃ¼yÃ¼k olduÄŸu yÃ¶nÃ¼ gÃ¶sterir. EÄŸitim sÃ¼recinde gradyan, modelin kaybÄ±nÄ± (loss) azaltmak iÃ§in parametrelerin (aÄŸÄ±rlÄ±klarÄ±n) gÃ¼ncellenmesinde kullanÄ±lÄ±r. GradyanÄ±n tersine Ã§evrilmiÅŸ yÃ¶nÃ¼, kaybÄ± azaltan bir yÃ¶ndÃ¼r, bu nedenle gradyan iniÅŸi, modelin kaybÄ±nÄ± azaltmak iÃ§in gradyanÄ±n negatif yÃ¶nÃ¼nde adÄ±mlar atar.

**`2) Momentum:`** Momentum, gradyan iniÅŸinde bir tÃ¼r ivme saÄŸlayan bir parametredir. Momentum, mevcut gradyan deÄŸerinin bir kÄ±smÄ±nÄ± (genellikle 0 ile 1 arasÄ±nda bir deÄŸer) korur ve yeni gradyan deÄŸerini bu ivme ile birleÅŸtirir. Bu, gradyan iniÅŸini daha hÄ±zlÄ± ve daha istikrarlÄ± hale getirir, Ã¶zellikle yerel minimumlardan kaÃ§Ä±nma ve dÃ¼z Ã§anaklarda hÄ±zlanma gibi durumlarda faydalÄ±dÄ±r.


"""

checkpoint = ModelCheckpoint(
    f'/content/drive/MyDrive/AYZEK-Kanarya/models/vgg-16/vgg16_model1.h5',
     monitor='val_accuracy',
     verbose=1,
     save_best_only=True,
     mode = 'max'
)

"""**monitor:** Modelin performansÄ±nÄ± izlemek iÃ§in kullanÄ±lan metriÄŸi belirtir. Ã–rneÄŸin, 'val_accuracy' olarak belirtilirse, doÄŸrulama veri seti Ã¼zerinde doÄŸruluk (accuracy) metriÄŸi izlenir ve bu metriÄŸin en iyi olduÄŸu durumlarda model kaydedilir.

**verbose:** KullanÄ±cÄ±ya ilerleme durumu hakkÄ±nda bilgi verir. DeÄŸer 0 ise sessiz mod, 1 ise ilerleme Ã§ubuÄŸu, 2 ise her bir epoch iÃ§in bir satÄ±r Ã§Ä±ktÄ± saÄŸlar.
"""

earlystop = EarlyStopping(monitor='val_accuracy',
                          patience=5,
                          verbose=1,
                          mode = 'max')

"""** *italik metin*EarlyStopping**, eÄŸitim sÄ±rasÄ±nda modelin aÅŸÄ±rÄ± uyum (overfitting) yapmasÄ±nÄ± Ã¶nlemek iÃ§in kullanÄ±lan bir Keras geri Ã§aÄŸÄ±rÄ±sÄ±dÄ±r. EÄŸitim sÃ¼recinde modelin performansÄ±nÄ± izler ve belirli bir kriteri karÅŸÄ±ladÄ±ÄŸÄ±nda (Ã¶rneÄŸin, doÄŸrulama setindeki doÄŸruluk belirli bir sÃ¼re boyunca artmazsa veya kayÄ±p belirli bir sÃ¼re boyunca azalmazsa), eÄŸitimi otomatik olarak durdurur."""

result = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // val_generator.batch_size,
    epochs=15,
    callbacks = [earlystop, checkpoint])

train_loss = result.history['loss']
train_accuracy = result.history['accuracy']

# train loss ve train accuracy gÃ¶rselleÅŸtirilmesi
epochs = range(1, len(train_loss) + 1)

plt.plot(epochs, train_loss, 'b', label='Training loss')
plt.plot(epochs, train_accuracy, 'r', label='Training accuracy')
plt.title('Training Loss and Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss / Accuracy')
plt.legend()

plt.show()

"""from keras.models import load_model
model1 = load_model('/content/drive/MyDrive/AYZEK-Kanarya/models/vgg-16/vgg16_model1.h5')

test_loss, test_accuracy = model1.evaluate(test_generator, steps=len(test_generator))
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

# model ile tahmin etme
predictions = model.predict(test_generator)

# test verileri ve tahmin edilen deÄŸerler arasÄ±ndaki karÅŸÄ±laÅŸtÄ±rma
num_samples_to_visualize = 20
test_labels = []  # GerÃ§ek deÄŸerleri tutan boÅŸ liste
predicted_labels = []  # Tahmin edilen deÄŸerleri tutan boÅŸ liste

# test datalarÄ±ndan Ã¶rnekler
for i, (_, labels) in enumerate(test_generator):
    test_labels.extend(labels.argmax(axis=1))  # GerÃ§ek etiketleri al
    predicted_labels.extend(predictions.argmax(axis=1))  # Tahmin edilen etiketleri al
    if i == num_samples_to_visualize - 1:
        break

# SonuÃ§larÄ± gÃ¶rselleÅŸtir
plt.figure(figsize=(12, 8))
for i in range(num_samples_to_visualize):
    plt.subplot(5, 4, i + 1)
    plt.imshow(test_generator[i][0][0])  # Test resmini gÃ¶ster
    plt.title(f'Real: {test_labels[i]}, Predicted: {predicted_labels[i]}')
    plt.axis('off')

plt.tight_layout()
plt.show()
"""

